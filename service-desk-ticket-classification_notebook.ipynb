{"cells":[{"source":"![servicedesk](servicedesk.png)\n\nCleverSupport is a company at the forefront of AI innovation, specializing in the development of AI-driven solutions to enhance customer support services. Their latest endeavor is to engineer a text classification system that can automatically categorize customer complaints. \n\nYour role as a data scientist involves the creation of a sophisticated machine learning model that can accurately assign complaints to specific categories, such as mortgage, credit card, money transfers, debt collection, etc.","metadata":{"executionCancelledAt":null,"executionTime":165,"lastExecutedAt":1707667023665,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"CleverSupport is a company at the forefront of AI innovation, specializing in the development of AI-driven solutions to enhance customer support services. Their latest endeavor is to engineer a text classification system that can autonomously categorize customer complaints. \n\nYour role as a data scientist involves the creation of a sophisticated machine learning model that can accurately assign complaints to specific categories, such as technical issues, billing inquiries, cancellation requests, refunds, and product information requests."},"id":"e5870ae0-6165-459e-9c40-0f282883be7b","cell_type":"markdown"},{"source":"!pip install torchmetrics","metadata":{"executionCancelledAt":null,"executionTime":5283,"lastExecutedAt":1716396825306,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install torchmetrics","outputsMetadata":{"0":{"height":616,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedByKernel":"74be1145-956a-4a60-b428-c950742cfda6"},"id":"0dd4beb4-2329-4b0d-8a34-2354ee9c7fb4","cell_type":"code","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: torchmetrics in /home/repl/.local/lib/python3.8/site-packages (1.4.0.post0)\nRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.23.2)\nRequirement already satisfied: packaging>17.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /home/repl/.local/lib/python3.8/site-packages (from torchmetrics) (0.11.2)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.9.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>17.1->torchmetrics) (3.0.9)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.10.3.66)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\nRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->torchmetrics) (0.38.4)\n"}]},{"source":"from collections import Counter\nimport nltk, json\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1716396825358,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from collections import Counter\nimport nltk, json\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall","lastExecutedByKernel":"74be1145-956a-4a60-b428-c950742cfda6"},"id":"2fa90b61-0244-4236-aa93-e33a7a088eec","cell_type":"code","execution_count":15,"outputs":[]},{"source":"nltk.download('punkt')","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1716396825410,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"nltk.download('punkt')","outputsMetadata":{"0":{"height":59,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedByKernel":"74be1145-956a-4a60-b428-c950742cfda6"},"id":"37a51a81-1301-4a80-b8c6-716faaff4c5c","cell_type":"code","execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":"[nltk_data] Downloading package punkt to /home/repl/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"},{"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{},"execution_count":16}]},{"source":"# Import data and labels\nwith open(\"words.json\", 'r') as f1:\n    words = json.load(f1)\nwith open(\"text.json\", 'r') as f2:\n    text = json.load(f2)\nlabels = np.load('labels.npy')","metadata":{"executionCancelledAt":null,"executionTime":108,"lastExecutedAt":1716396825518,"lastExecutedByKernel":"74be1145-956a-4a60-b428-c950742cfda6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import data and labels\nwith open(\"words.json\", 'r') as f1:\n    words = json.load(f1)\nwith open(\"text.json\", 'r') as f2:\n    text = json.load(f2)\nlabels = np.load('labels.npy')"},"id":"e1b12eaf-e55c-422c-94a2-b0197c465a1b","cell_type":"code","execution_count":17,"outputs":[]},{"source":"# Dictionaries to store the word to index mappings and vice versa\nword2idx = {o:i for i,o in enumerate(words)}\nidx2word = {i:o for i,o in enumerate(words)}\n\n# Looking up the mapping dictionary and assigning the index to the respective words\nfor i, sentence in enumerate(text):\n    text[i] = [word2idx[word] if word in word2idx else 0 for word in sentence]\n    \n# Defining a function that either shortens sentences or pads sentences with 0 to a fixed length\ndef pad_input(sentences, seq_len):\n    features = np.zeros((len(sentences), seq_len),dtype=int)\n    for ii, review in enumerate(sentences):\n        if len(review) != 0:\n            features[ii, -len(review):] = np.array(review)[:seq_len]\n    return features\n\ntext = pad_input(text, 50)","metadata":{"executionCancelledAt":null,"executionTime":254,"lastExecutedAt":1716396825772,"lastExecutedByKernel":"74be1145-956a-4a60-b428-c950742cfda6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Dictionaries to store the word to index mappings and vice versa\nword2idx = {o:i for i,o in enumerate(words)}\nidx2word = {i:o for i,o in enumerate(words)}\n\n# Looking up the mapping dictionary and assigning the index to the respective words\nfor i, sentence in enumerate(text):\n    text[i] = [word2idx[word] if word in word2idx else 0 for word in sentence]\n    \n# Defining a function that either shortens sentences or pads sentences with 0 to a fixed length\ndef pad_input(sentences, seq_len):\n    features = np.zeros((len(sentences), seq_len),dtype=int)\n    for ii, review in enumerate(sentences):\n        if len(review) != 0:\n            features[ii, -len(review):] = np.array(review)[:seq_len]\n    return features\n\ntext = pad_input(text, 50)"},"id":"d630badb-23dd-4368-9a96-e2b478ad5cff","cell_type":"code","execution_count":18,"outputs":[]},{"source":"# Splitting dataset\ntrain_text, test_text, train_label, test_label = train_test_split(text, labels, test_size=0.2, random_state=42)\n\ntrain_data = TensorDataset(torch.from_numpy(train_text), torch.from_numpy(train_label).long())\ntest_data = TensorDataset(torch.from_numpy(test_text), torch.from_numpy(test_label).long())","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1716396825826,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Splitting dataset\ntrain_text, test_text, train_label, test_label = train_test_split(text, labels, test_size=0.2, random_state=42)\n\ntrain_data = TensorDataset(torch.from_numpy(train_text), torch.from_numpy(train_label).long())\ntest_data = TensorDataset(torch.from_numpy(test_text), torch.from_numpy(test_label).long())","lastExecutedByKernel":"74be1145-956a-4a60-b428-c950742cfda6"},"id":"f2654836-631f-415e-9922-5ab3bafaaafa","cell_type":"code","execution_count":19,"outputs":[]},{"source":"# Start coding here","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1716396825874,"lastExecutedByKernel":"74be1145-956a-4a60-b428-c950742cfda6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Start coding here"},"id":"d2b3c50c-66b1-40ed-a17c-038e7addc7ec","cell_type":"code","execution_count":20,"outputs":[]},{"source":"## Step 1: Define the CNN Classifier\nWe will start by defining a class for the CNN classifier in PyTorch.","metadata":{},"cell_type":"markdown","id":"e2f8628b-3db7-4670-895b-74aa72000ebe"},{"source":"class CNNClassifier(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, num_classes, seq_len):\n        super(CNNClassifier, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.conv1d = nn.Conv1d(in_channels=embedding_dim, out_channels=128, kernel_size=5, stride=1)\n        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n        self.fc = nn.Linear(128 * ((seq_len - 4) // 2), num_classes)\n        \n    def forward(self, x):\n        x = self.embedding(x)\n        x = x.permute(0, 2, 1)  # Permute to match input shape for Conv1d (batch_size, embedding_dim, seq_len)\n        x = F.relu(self.conv1d(x))\n        x = self.pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n# Parameters\nvocab_size = len(word2idx)\nembedding_dim = 50\nnum_classes = len(set(labels))\nseq_len = 50\n\n# Instantiate the model\nmodel = CNNClassifier(vocab_size, embedding_dim, num_classes, seq_len)","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1716396825926,"lastExecutedByKernel":"74be1145-956a-4a60-b428-c950742cfda6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"class CNNClassifier(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, num_classes, seq_len):\n        super(CNNClassifier, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.conv1d = nn.Conv1d(in_channels=embedding_dim, out_channels=128, kernel_size=5, stride=1)\n        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n        self.fc = nn.Linear(128 * ((seq_len - 4) // 2), num_classes)\n        \n    def forward(self, x):\n        x = self.embedding(x)\n        x = x.permute(0, 2, 1)  # Permute to match input shape for Conv1d (batch_size, embedding_dim, seq_len)\n        x = F.relu(self.conv1d(x))\n        x = self.pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n# Parameters\nvocab_size = len(word2idx)\nembedding_dim = 50\nnum_classes = len(set(labels))\nseq_len = 50\n\n# Instantiate the model\nmodel = CNNClassifier(vocab_size, embedding_dim, num_classes, seq_len)"},"cell_type":"code","id":"294591d8-beac-4e3c-801e-85376896e02b","outputs":[],"execution_count":21},{"source":"## Step 2: Define the Optimizer and Loss Function","metadata":{},"cell_type":"markdown","id":"cd46f633-bbe2-4ac2-ba2e-1917e7f9b0e9"},{"source":"# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1716396825974,"lastExecutedByKernel":"74be1145-956a-4a60-b428-c950742cfda6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)"},"cell_type":"code","id":"769fd607-d910-4aa8-8e68-eb3126015f77","outputs":[],"execution_count":22},{"source":"## Step 3: Train the Classifier\nWe will train the classifier for 3 epochs using the DataLoader to batch the training data.","metadata":{},"cell_type":"markdown","id":"9f947cc2-4789-4fa0-8688-23ef4e5705a1"},{"source":"# DataLoader\ntrain_loader = DataLoader(train_data, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n\n# Training function\ndef train_model(model, train_loader, criterion, optimizer, epochs=3):\n    model.train()\n    for epoch in range(epochs):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n\n# Train the model\ntrain_model(model, train_loader, criterion, optimizer)","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":80,"type":"stream"}}},"cell_type":"code","id":"c49b0a7c-a0d3-42ab-b3c6-7abdb0fed298","outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/3, Loss: 1.2620103359222412\nEpoch 2/3, Loss: 0.7263175249099731\nEpoch 3/3, Loss: 0.6771326065063477\n"}],"execution_count":23},{"source":"## Step 4: Test the Classifier and Make Predictions","metadata":{},"cell_type":"markdown","id":"8733bf17-6a87-415c-8ea3-4ed267b24e15"},{"source":"# Function to make predictions and store them in 'predicted'\ndef evaluate_model(model, test_loader):\n    model.eval()\n    predicted = []\n    true_labels = []\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            predicted.extend(preds.numpy())\n            true_labels.extend(labels.numpy())\n    return predicted, true_labels\n\n# Get predictions\npredicted, true_labels = evaluate_model(model, test_loader)\npredictions = torch.tensor(predicted)  # Ensure predictions is a tensor","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1716396827250,"lastExecutedByKernel":"74be1145-956a-4a60-b428-c950742cfda6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Function to make predictions and store them in 'predicted'\ndef evaluate_model(model, test_loader):\n    model.eval()\n    predicted = []\n    true_labels = []\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            predicted.extend(preds.numpy())\n            true_labels.extend(labels.numpy())\n    return predicted, true_labels\n\n# Get predictions\npredicted, true_labels = evaluate_model(model, test_loader)\npredictions = torch.tensor(predicted)  # Ensure predictions is a tensor"},"cell_type":"code","id":"9b4c6577-1785-4612-8413-f138b1252e15","outputs":[],"execution_count":24},{"source":"## Step 5: Calculate Metrics\nWe'll use torchmetrics to calculate accuracy, precision, and recall.","metadata":{},"cell_type":"markdown","id":"b8b568d4-6414-4b2a-abdf-7b552330265a"},{"source":"# Calculate metrics\naccuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)(predictions, torch.tensor(true_labels))\nprecision = Precision(task=\"multiclass\", num_classes=num_classes, average='macro')(predictions, torch.tensor(true_labels))\nrecall = Recall(task=\"multiclass\", num_classes=num_classes, average='macro')(predictions, torch.tensor(true_labels))\n\nprint(f'Accuracy: {accuracy:.4f}')\nprint(f'Precision: {precision:.4f}')\nprint(f'Recall: {recall:.4f}')","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1716396827302,"lastExecutedByKernel":"74be1145-956a-4a60-b428-c950742cfda6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Calculate metrics\naccuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)(predictions, torch.tensor(true_labels))\nprecision = Precision(task=\"multiclass\", num_classes=num_classes, average='macro')(predictions, torch.tensor(true_labels))\nrecall = Recall(task=\"multiclass\", num_classes=num_classes, average='macro')(predictions, torch.tensor(true_labels))\n\nprint(f'Accuracy: {accuracy:.4f}')\nprint(f'Precision: {precision:.4f}')\nprint(f'Recall: {recall:.4f}')","outputsMetadata":{"0":{"height":80,"type":"stream"}}},"cell_type":"code","id":"40ccfdb2-c8b5-40de-8ada-92257268c6cc","outputs":[{"output_type":"stream","name":"stdout","text":"Accuracy: 0.6610\nPrecision: 0.6798\nRecall: 0.6604\n"}],"execution_count":25},{"source":"# Their solution","metadata":{},"cell_type":"markdown","id":"5d0026aa-58a2-4dd6-8a7e-1bf59eedc6eb"},{"source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall\n\nbatch_size = 400\ntrain_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\ntest_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)\n\n# Define the classifier class\nclass TicketClassifier(nn.Module):\n    def __init__(self, vocab_size, embed_dim, target_size):\n        super(TicketClassifier, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.conv = nn.Conv1d(embed_dim, embed_dim, kernel_size=3, stride=1, padding=1)\n        self.fc = nn.Linear(embed_dim, target_size)\n\n    def forward(self, text):\n        embedded = self.embedding(text).permute(0, 2, 1)\n        conved = F.relu(self.conv(embedded))\n        conved = conved.mean(dim=2) \n        return self.fc(conved)\n\n\nvocab_size = len(word2idx) + 1\ntarget_size = len(np.unique(labels))\nembedding_dim = 64\n\n# Create an instance of the TicketClassifier class\nmodel = TicketClassifier(vocab_size, embedding_dim, target_size)\n\nlr = 0.05\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\nepochs = 3\n\n# Train the model\nmodel.train()\nfor i in range(epochs):\n    running_loss, num_processed = 0,0\n    for inputs, labels in train_loader:\n        model.zero_grad()\n        output = model(inputs)\n        loss = criterion(output, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        num_processed += len(inputs)\n    print(f\"Epoch: {i+1}, Loss: {running_loss/num_processed}\")\n\n\naccuracy_metric = Accuracy(task='multiclass', num_classes=5)\nprecision_metric = Precision(task='multiclass', num_classes=5, average=None)\nrecall_metric = Recall(task='multiclass', num_classes=5, average=None)\n\n# Evaluate model on test set\nmodel.eval()\npredicted = []\n\nfor i, (inputs, labels) in enumerate(test_loader):\n    output = model(inputs)\n    cat = torch.argmax(output, dim=-1)\n    predicted.extend(cat.tolist())\n    accuracy_metric(cat, labels)\n    precision_metric(cat, labels)\n    recall_metric(cat, labels)\n\naccuracy = accuracy_metric.compute().item()\nprecision = precision_metric.compute().tolist()\nrecall = recall_metric.compute().tolist()\nprint('Accuracy:', accuracy)\nprint('Precision (per class):', precision)\nprint('Recall (per class):', recall)","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":143,"type":"stream"}}},"cell_type":"code","id":"a8223348-6d55-4a82-af97-5a584692b8a9","outputs":[{"output_type":"stream","name":"stdout","text":"Epoch: 1, Loss: 0.00380037334561348\nEpoch: 2, Loss: 0.0018858914971351622\nEpoch: 3, Loss: 0.0009005416296422482\nAccuracy: 0.7839999794960022\nPrecision (per class): [0.700507640838623, 0.7253885865211487, 0.875, 0.7566137313842773, 0.8515284061431885]\nRecall (per class): [0.71875, 0.7368420958518982, 0.7777777910232544, 0.7447916865348816, 0.9285714030265808]\n"}],"execution_count":26},{"source":"## Comparison Summary\nMy Code:\n- Uses a CNN model (CNNClassifier) with an embedding layer, a convolutional layer, and a fully connected layer.\n- Defines the model with nn.Embedding, nn.Conv1d, nn.MaxPool1d, and nn.Linear.\n- Utilizes torchmetrics for accuracy, precision, and recall calculations.\n- Optimizes the model using the Adam optimizer with a learning rate of 0.001.\n- Data is padded to a fixed sequence length of 50.\n- Trains the model using a batch size of 32 and evaluates on a separate test set.\n\nProposed Solution:\n- Uses a CNN model (TicketClassifier) with an embedding layer, a convolutional layer, and a fully connected layer.\n- Defines the model with nn.Embedding, nn.Conv1d, and nn.Linear.\n- Utilizes torchmetrics for accuracy, precision, and recall calculations.\n- Optimizes the model using the Adam optimizer with a learning rate of 0.05.\n- Data is padded to a fixed sequence length of 50.\n- Trains the model using a batch size of 400 and evaluates on a separate test set.","metadata":{},"cell_type":"markdown","id":"021ec1aa-d378-40e7-bf01-efbcb94b9c40"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}